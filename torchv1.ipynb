{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa886ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# California Housing veri setini yükleme\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae602b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
      "          37.88      , -122.23      ],\n",
      "       [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
      "          37.86      , -122.22      ],\n",
      "       [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
      "          37.85      , -122.24      ],\n",
      "       ...,\n",
      "       [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
      "          39.43      , -121.22      ],\n",
      "       [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
      "          39.43      , -121.32      ],\n",
      "       [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
      "          39.37      , -121.24      ]]), 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]), 'frame': None, 'target_names': ['MedHouseVal'], 'feature_names': ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude'], 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block group\\n        - HouseAge      median house age in block group\\n        - AveRooms      average number of rooms per household\\n        - AveBedrms     average number of bedrooms per household\\n        - Population    block group population\\n        - AveOccup      average number of household members\\n        - Latitude      block group latitude\\n        - Longitude     block group longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}\n"
     ]
    }
   ],
   "source": [
    "print(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c611eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   8.3252,   41.0000,    6.9841,  ...,    2.5556,   37.8800,\n",
      "         -122.2300],\n",
      "        [   8.3014,   21.0000,    6.2381,  ...,    2.1098,   37.8600,\n",
      "         -122.2200],\n",
      "        [   7.2574,   52.0000,    8.2881,  ...,    2.8023,   37.8500,\n",
      "         -122.2400],\n",
      "        ...,\n",
      "        [   1.7000,   17.0000,    5.2055,  ...,    2.3256,   39.4300,\n",
      "         -121.2200],\n",
      "        [   1.8672,   18.0000,    5.3295,  ...,    2.1232,   39.4300,\n",
      "         -121.3200],\n",
      "        [   2.3886,   16.0000,    5.2547,  ...,    2.6170,   39.3700,\n",
      "         -121.2400]])\n",
      "tensor([4.5260, 3.5850, 3.5210,  ..., 0.9230, 0.8470, 0.8940])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import torch\n",
    "\n",
    "# California Housing veri setini yükleme\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Özellikler ve hedef değişkenini al\n",
    "X = housing.data  # Bu, NumPy dizisi zaten\n",
    "y = housing.target  # Hedef değişken\n",
    "\n",
    "# PyTorch tensor'lerine dönüştürme\n",
    "X_tensor = torch.from_numpy(X).float()  # X verisini tensor'e dönüştürme\n",
    "y_tensor = torch.from_numpy(y).float()  # Hedef verisini tensor'e dönüştürme\n",
    "\n",
    "print(X_tensor)\n",
    "print(y_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56d49159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20640, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a48b8a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20640])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7eaa1025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83c2681e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[136, 133, 126],\n",
       "        [137, 134, 127],\n",
       "        [138, 135, 128],\n",
       "        ...,\n",
       "        [145, 142, 137],\n",
       "        [145, 142, 137],\n",
       "        [143, 140, 135]],\n",
       "\n",
       "       [[136, 133, 126],\n",
       "        [138, 135, 128],\n",
       "        [138, 135, 128],\n",
       "        ...,\n",
       "        [145, 142, 137],\n",
       "        [145, 142, 137],\n",
       "        [143, 140, 135]],\n",
       "\n",
       "       [[137, 134, 127],\n",
       "        [137, 134, 127],\n",
       "        [137, 134, 127],\n",
       "        ...,\n",
       "        [145, 142, 137],\n",
       "        [145, 142, 137],\n",
       "        [144, 141, 136]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[188, 189, 184],\n",
       "        [185, 186, 181],\n",
       "        [190, 191, 186],\n",
       "        ...,\n",
       "        [141, 136, 130],\n",
       "        [139, 134, 128],\n",
       "        [139, 134, 128]],\n",
       "\n",
       "       [[179, 180, 175],\n",
       "        [179, 180, 175],\n",
       "        [183, 184, 179],\n",
       "        ...,\n",
       "        [125, 120, 114],\n",
       "        [120, 115, 109],\n",
       "        [120, 115, 109]],\n",
       "\n",
       "       [[169, 170, 165],\n",
       "        [173, 174, 169],\n",
       "        [175, 176, 171],\n",
       "        ...,\n",
       "        [116, 111, 105],\n",
       "        [109, 104,  98],\n",
       "        [108, 103,  97]]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kedy=np.array(Image.open(\"kedi1.jpg\").resize((224,224)))\n",
    "kedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6160531d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kedytorch=torch.from_numpy(kedy)\n",
    "\n",
    "np.shape(kedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bde0a24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 224, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kedytorch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "093c78c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0433d5ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret 'torch.uint8' as a data type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mimsave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkedi\u001b[39m\u001b[38;5;124m\"\u001b[39m,kedytorch)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\pyplot.py:2200\u001b[0m, in \u001b[0;36mimsave\u001b[1;34m(fname, arr, **kwargs)\u001b[0m\n\u001b[0;32m   2198\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(matplotlib\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave)\n\u001b[0;32m   2199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimsave\u001b[39m(fname, arr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m matplotlib\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave(fname, arr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\image.py:1652\u001b[0m, in \u001b[0;36mimsave\u001b[1;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m   1650\u001b[0m     sm \u001b[38;5;241m=\u001b[39m cm\u001b[38;5;241m.\u001b[39mScalarMappable(cmap\u001b[38;5;241m=\u001b[39mcmap)\n\u001b[0;32m   1651\u001b[0m     sm\u001b[38;5;241m.\u001b[39mset_clim(vmin, vmax)\n\u001b[1;32m-> 1652\u001b[0m     rgba \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mto_rgba(arr, \u001b[38;5;28mbytes\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pil_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1654\u001b[0m     pil_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\cm.py:466\u001b[0m, in \u001b[0;36mScalarMappable.to_rgba\u001b[1;34m(self, x, alpha, bytes, norm)\u001b[0m\n\u001b[0;32m    464\u001b[0m     alpha \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8(alpha \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m)\n\u001b[0;32m    465\u001b[0m m, n \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m--> 466\u001b[0m xx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(shape\u001b[38;5;241m=\u001b[39m(m, n, \u001b[38;5;241m4\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    467\u001b[0m xx[:, :, :\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    468\u001b[0m xx[:, :, \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m alpha\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot interpret 'torch.uint8' as a data type"
     ]
    }
   ],
   "source": [
    "plt.imsave(\"kedi\",kedytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce23be4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8516edc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
