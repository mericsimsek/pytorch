{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f9e0fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden=nn.Linear(784,256)#bura ilk parametre giriş 2.si gizli katman \n",
    "        \n",
    "        \n",
    "        self.output=nn.Linear(256,10)#burada ilk parametre gizli katman ikincisi çıkış \n",
    "        \n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "        \n",
    "    def printle(self,x):\n",
    "        x=self.hidden(x)\n",
    "        x=self.output(x)\n",
    "        x=self.sigmoid(x)\n",
    "        x=self.softmax(x)\n",
    "        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ee8739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=network()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d56fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden=nn.Linear(784,256)#bura ilk parametre giriş 2.si gizli katman \n",
    "        \n",
    "        \n",
    "        self.output=nn.Linear(256,10)#burada ilk parametre gizli katman ikincisi çıkış \n",
    "        \n",
    "    def printl(self,x):\n",
    "        x=F.sigmoid(self.hidden(x))\n",
    "        \n",
    "        x=F.sigmoid(self.sigmoid(x),dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f134d717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=network()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62ab43e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0305,  0.0277, -0.0115,  ...,  0.0302,  0.0042, -0.0130],\n",
       "        [-0.0110,  0.0110,  0.0014,  ...,  0.0088,  0.0016, -0.0226],\n",
       "        [-0.0172, -0.0341,  0.0286,  ...,  0.0012,  0.0356,  0.0111],\n",
       "        ...,\n",
       "        [ 0.0182,  0.0184,  0.0353,  ..., -0.0067, -0.0146, -0.0226],\n",
       "        [-0.0100,  0.0241,  0.0252,  ...,  0.0331,  0.0221,  0.0340],\n",
       "        [-0.0253,  0.0064,  0.0116,  ...,  0.0276, -0.0330, -0.0128]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.hidden.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ea8ec76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0377, -0.0545, -0.0372, -0.0581,  0.0369, -0.0171, -0.0120,  0.0475,\n",
       "        -0.0192, -0.0303], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.output.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39a14934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.hidden.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b48a0ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0122,  0.0003,  0.0123,  ..., -0.0062,  0.0019,  0.0110],\n",
       "        [ 0.0025,  0.0082,  0.0144,  ...,  0.0005, -0.0073, -0.0078],\n",
       "        [-0.0035,  0.0036,  0.0018,  ..., -0.0069, -0.0067, -0.0123],\n",
       "        ...,\n",
       "        [-0.0017, -0.0113,  0.0287,  ..., -0.0177,  0.0070,  0.0113],\n",
       "        [-0.0033,  0.0095,  0.0064,  ..., -0.0044,  0.0085,  0.0211],\n",
       "        [-0.0079, -0.0023,  0.0087,  ...,  0.0038, -0.0095,  0.0075]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.hidden.weight.data.normal_(std=0.01)#hidden katmanındaki ağırlıkların hepsini N(0, 0.01^2) dağılımına göre rastgele değerlere ayarlayacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5ba5d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9.91M/9.91M [00:13<00:00, 711kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28.9k/28.9k [00:00<00:00, 161kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.65M/1.65M [00:01<00:00, 1.06MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.54k/4.54k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Verileri dönüştürme işlemi\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# MNIST veri setini yükleme\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# DataLoader oluşturma\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2b62cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(784, 10)  # Örneğin, 784 giriş, 10 çıkış\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "596a01ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc077275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Örnek veri: 64 örneklik bir batch, 28x28 boyutunda\n",
    "inputs = torch.randn(64, 1, 28, 28)\n",
    "\n",
    "# Veriyi düzleştirme: (batch_size, 784)\n",
    "inputs = inputs.view(64, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b632721d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(inputs)\n",
    "\n",
    "# Çıktıyı inceleyin\n",
    "print(outputs.shape)  # Çıktı: torch.Size([64, 10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e61456",
   "metadata": {},
   "outputs": [],
   "source": [
    "Veri Şeklinin Düzleştirilmesi\n",
    "MNIST gibi veri setlerinden alınan görüntüler genellikle 2 boyutludur (28x28 piksel). Ancak bu iki boyutlu yapı, bir tam bağlı katman tarafından işlenemez. Bu nedenle:\n",
    "\n",
    "Görüntünün her pikselini bir özellik (feature) olarak ele alırız.\n",
    "28x28 = 784 pikseli bir vektör haline getiririz (flattening/düzleştirme).\n",
    "Düzleştirme işlemi şunu yapar:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "# Önce: (64, 1, 28, 28) -> Batch size: 64, Kanal: 1, Yükseklik: 28, Genişlik: 28\n",
    "inputs = inputs.view(64, -1)\n",
    "# Sonra: (64, 784) -> Batch size: 64, Özellik sayısı: 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8c9d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "buralarda kullanlır\n",
    "1. Tam Bağlı Katmanlara (Fully Connected Layers) Geçmeden Önce\n",
    "Tam bağlı katmanlar (nn.Linear) giriş olarak her bir örneği bir vektör olarak bekler. Eğer modelinizde tam bağlı bir katman varsa ve giriş veriniz çok boyutluysa (örneğin, bir görüntü), tam bağlı katmanla işlenebilmesi için düzleştirme yapmanız gerekir.\n",
    "\n",
    "Ne zaman:\n",
    "\n",
    "Convolutional Neural Network (CNN) sonrası:\n",
    "Örneğin, CNN çıkışını tam bağlı bir katmana bağlamadan önce.\n",
    "python\n",
    "Kodu kopyala\n",
    "x = x.view(x.size(0), -1)  # Batch boyutunu koruyarak düzleştirme\n",
    "Örnek:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 16, kernel_size=3)\n",
    "        self.fc = nn.Linear(16 * 26 * 26, 10)  # CNN sonrası düzleştirilmiş giriş\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)  # (batch_size, 16, 26, 26)\n",
    "        x = x.view(x.size(0), -1)  # Düzleştirme\n",
    "        x = self.fc(x)  # (batch_size, 10)\n",
    "        return x\n",
    "2. Doğrudan Düzleştirilmiş Veri Kullandığınızda\n",
    "Eğer veri setiniz 2D (örneğin, görüntü) veya 3D (örneğin, ses) formatındaysa, ancak modeliniz bu verileri 1D vektör olarak bekliyorsa, düzleştirme yapmanız gerekir.\n",
    "\n",
    "Örnek:\n",
    "\n",
    "MNIST (28x28 görüntüler):\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "inputs = inputs.view(inputs.size(0), -1)  # (batch_size, 784)\n",
    "CIFAR-10 (3 kanallı 32x32 görüntüler):\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "inputs = inputs.view(inputs.size(0), -1)  # (batch_size, 3072)\n",
    "3. Convolutional Neural Network (CNN) Olmadığında\n",
    "Eğer yalnızca tam bağlı katmanlardan oluşan bir model (örneğin, bir derin perceptron) kullanıyorsanız, düzleştirme işlemini modelin giriş aşamasında yapmanız gerekir.\n",
    "\n",
    "Örnek:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Düzleştirme\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "4. Transfer Learning ve Önceden Eğitilmiş Modellerde\n",
    "Transfer öğrenme için önceden eğitilmiş bir CNN modeli kullanıyorsanız, genelde son convolutional katmanın çıktısını düzleştirmeniz gerekebilir.\n",
    "\n",
    "Örnek:\n",
    "\n",
    "python\n",
    "Kodu kopyala\n",
    "import torchvision.models as models\n",
    "\n",
    "# Önceden eğitilmiş model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Özellik çıkarımı için\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "features = model(x)\n",
    "\n",
    "# Düzleştirme işlemi (gerekliyse)\n",
    "features = features.view(features.size(0), -1)\n",
    "5. Özellikleri Manuel Olarak Düzleştirmeniz Gerekmediğinde\n",
    "Düzleştirme yapmanıza gerek olmayan durumlar:\n",
    "\n",
    "Eğer CNN veya RNN katmanlarını birbiri ardına kullanıyorsanız.\n",
    "Veriniz doğrudan tam bağlı katmana uygun formatta zaten bir vektörse (örneğin, 1D tensörler).\n",
    "Özet:\n",
    "Düzleştirme işlemini kullanmanız gereken durumlar:\n",
    "\n",
    "CNN sonrası tam bağlı katmanlara geçiyorsanız.\n",
    "Giriş veriniz çok boyutluysa ancak modeliniz 1D tensör bekliyorsa.\n",
    "Önceden eğitilmiş modellerde convolutional çıktıdan tam bağlı katmana geçiş yapıyorsanız.\n",
    "Düzleştirme ihtiyacı, kullandığınız modelin mimarisine ve işlediğiniz verinin formatına bağlıdır. CNN kullanıyorsanız, düzleştirme genelde yalnızca tam bağlı katman öncesinde yapılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a45f585b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# DataLoader'dan veri almak\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Tensörlerin boyutlarını kontrol edin\n",
    "print(images.shape)  # Çıktı: torch.Size([64, 1, 28, 28])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2071d5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 784])\n"
     ]
    }
   ],
   "source": [
    "# Görselleri yeniden şekillendirme\n",
    "images = images.view(64, 1, 784)  # (batch_size, channels, flattened_size)\n",
    "print(images.shape)  # Çıktı: torch.Size([64, 1, 784])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "daf73aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def view_classify(img, ps):\n",
    "    \"\"\"Görüntüyü ve sınıflandırma sonuçlarını görselleştirir.\"\"\"\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), nrows=2)\n",
    "    ax1.imshow(img.numpy().squeeze(), cmap='gray')\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Sınıflandırma Olasılıkları')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b47ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx=0\n",
    "ps=model.forward(images[img_idx,:])\n",
    "img=images[img_idx]\n",
    "view_classify(img.view(1,28,28),ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0cd1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b7831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a83489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Basit Model Tanımı\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(784, 10)  # 784 giriş, 10 sınıf çıkışı\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Görselleştirme Fonksiyonu\n",
    "def view_classify(img, ps):\n",
    "    ps = ps.detach().numpy().squeeze()  # Olasılıkları numpy'a dönüştür\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6, 9), nrows=2)\n",
    "\n",
    "    # Görüntüyü göster\n",
    "    ax1.imshow(img.numpy().squeeze(), cmap='gray')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    # Sınıflandırma olasılıklarını görselleştir\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Sınıflandırma Olasılıkları')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Modeli oluşturma\n",
    "model = SimpleModel()\n",
    "\n",
    "# Daha küçük veri (2 örnek, 784 özellik)\n",
    "images = torch.randn(2, 784)  # 2 örnek, her biri 28x28 boyutunda düzleştirilmiş\n",
    "\n",
    "# Belirli bir örneği seçmek\n",
    "img_idx = 0\n",
    "single_image = images[img_idx, :].unsqueeze(0)  # Batch boyutu eklemek için unsqueeze kullanıyoruz\n",
    "\n",
    "# Modeli çalıştır ve olasılıkları al\n",
    "logits = model(single_image)  # Modelin çıkışı\n",
    "ps = nn.functional.softmax(logits, dim=1)  # Olasılık hesaplama\n",
    "\n",
    "# Görüntüyü orijinal boyutuna döndür (28x28)\n",
    "img = images[img_idx, :].view(1, 28, 28)\n",
    "\n",
    "# Görselleştirme\n",
    "view_classify(img, ps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab50ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f7b4f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960e48f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f695fbb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa8ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c194a20",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:2059\u001b[0m\n\u001b[0;32m   2043\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m   2044\u001b[0m \u001b[38;5;66;03m# Import most common subpackages\u001b[39;00m\n\u001b[0;32m   2045\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2050\u001b[0m \n\u001b[0;32m   2051\u001b[0m \u001b[38;5;66;03m# needs to be before import torch.nn as nn to avoid circular dependencies\u001b[39;00m\n\u001b[0;32m   2052\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[0;32m   2053\u001b[0m     enable_grad \u001b[38;5;28;01mas\u001b[39;00m enable_grad,\n\u001b[0;32m   2054\u001b[0m     inference_mode \u001b[38;5;28;01mas\u001b[39;00m inference_mode,\n\u001b[0;32m   2055\u001b[0m     no_grad \u001b[38;5;28;01mas\u001b[39;00m no_grad,\n\u001b[0;32m   2056\u001b[0m     set_grad_enabled \u001b[38;5;28;01mas\u001b[39;00m set_grad_enabled,\n\u001b[0;32m   2057\u001b[0m )\n\u001b[1;32m-> 2059\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m   2060\u001b[0m     __config__ \u001b[38;5;28;01mas\u001b[39;00m __config__,\n\u001b[0;32m   2061\u001b[0m     __future__ \u001b[38;5;28;01mas\u001b[39;00m __future__,\n\u001b[0;32m   2062\u001b[0m     _awaits \u001b[38;5;28;01mas\u001b[39;00m _awaits,\n\u001b[0;32m   2063\u001b[0m     autograd \u001b[38;5;28;01mas\u001b[39;00m autograd,\n\u001b[0;32m   2064\u001b[0m     backends \u001b[38;5;28;01mas\u001b[39;00m backends,\n\u001b[0;32m   2065\u001b[0m     cpu \u001b[38;5;28;01mas\u001b[39;00m cpu,\n\u001b[0;32m   2066\u001b[0m     cuda \u001b[38;5;28;01mas\u001b[39;00m cuda,\n\u001b[0;32m   2067\u001b[0m     distributed \u001b[38;5;28;01mas\u001b[39;00m distributed,\n\u001b[0;32m   2068\u001b[0m     distributions \u001b[38;5;28;01mas\u001b[39;00m distributions,\n\u001b[0;32m   2069\u001b[0m     fft \u001b[38;5;28;01mas\u001b[39;00m fft,\n\u001b[0;32m   2070\u001b[0m     futures \u001b[38;5;28;01mas\u001b[39;00m futures,\n\u001b[0;32m   2071\u001b[0m     hub \u001b[38;5;28;01mas\u001b[39;00m hub,\n\u001b[0;32m   2072\u001b[0m     jit \u001b[38;5;28;01mas\u001b[39;00m jit,\n\u001b[0;32m   2073\u001b[0m     linalg \u001b[38;5;28;01mas\u001b[39;00m linalg,\n\u001b[0;32m   2074\u001b[0m     mps \u001b[38;5;28;01mas\u001b[39;00m mps,\n\u001b[0;32m   2075\u001b[0m     mtia \u001b[38;5;28;01mas\u001b[39;00m mtia,\n\u001b[0;32m   2076\u001b[0m     multiprocessing \u001b[38;5;28;01mas\u001b[39;00m multiprocessing,\n\u001b[0;32m   2077\u001b[0m     nested \u001b[38;5;28;01mas\u001b[39;00m nested,\n\u001b[0;32m   2078\u001b[0m     nn \u001b[38;5;28;01mas\u001b[39;00m nn,\n\u001b[0;32m   2079\u001b[0m     optim \u001b[38;5;28;01mas\u001b[39;00m optim,\n\u001b[0;32m   2080\u001b[0m     overrides \u001b[38;5;28;01mas\u001b[39;00m overrides,\n\u001b[0;32m   2081\u001b[0m     profiler \u001b[38;5;28;01mas\u001b[39;00m profiler,\n\u001b[0;32m   2082\u001b[0m     sparse \u001b[38;5;28;01mas\u001b[39;00m sparse,\n\u001b[0;32m   2083\u001b[0m     special \u001b[38;5;28;01mas\u001b[39;00m special,\n\u001b[0;32m   2084\u001b[0m     testing \u001b[38;5;28;01mas\u001b[39;00m testing,\n\u001b[0;32m   2085\u001b[0m     types \u001b[38;5;28;01mas\u001b[39;00m types,\n\u001b[0;32m   2086\u001b[0m     utils \u001b[38;5;28;01mas\u001b[39;00m utils,\n\u001b[0;32m   2087\u001b[0m     xpu \u001b[38;5;28;01mas\u001b[39;00m xpu,\n\u001b[0;32m   2088\u001b[0m )\n\u001b[0;32m   2089\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m windows \u001b[38;5;28;01mas\u001b[39;00m windows\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;66;03m# Quantized, sparse, AO, etc. should be last to get imported, as nothing\u001b[39;00m\n\u001b[0;32m   2093\u001b[0m \u001b[38;5;66;03m# is expected to depend on them.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\hub.py:64\u001b[0m\n\u001b[0;32m     60\u001b[0m         sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm  \u001b[38;5;66;03m# If tqdm is installed use it, otherwise use the fake wrapper\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m     tqdm \u001b[38;5;241m=\u001b[39m _Faketqdm\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tqdm\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_monitor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TMonitor, TqdmSynchronisationWarning\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tqdm_pandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm_pandas\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcli\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m main  \u001b[38;5;66;03m# TODO: remove in v5.0.0\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgui\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;28;01mas\u001b[39;00m tqdm_gui  \u001b[38;5;66;03m# TODO: remove in v5.0.0\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgui\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m trange \u001b[38;5;28;01mas\u001b[39;00m tgrange  \u001b[38;5;66;03m# TODO: remove in v5.0.0\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tqdm\\cli.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m literal_eval \u001b[38;5;28;01mas\u001b[39;00m numeric\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TqdmKeyError, TqdmTypeError, tqdm\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     12\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     13\u001b[0m log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tqdm\\version.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"`tqdm` version detector. Precedence: installed dist, git, 'UNKNOWN'.\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dist_ver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1130\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MNIST veri setini yükleme ve veriyi normalize etme\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# DataLoader ile veriyi batch'ler halinde alacak şekilde ayarlama\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# MLP Modeli tanımlama\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)  # İlk katman: 784 giriş (28x28), 128 çıkış\n",
    "        self.fc2 = nn.Linear(128, 64)   # İkinci katman: 128 giriş, 64 çıkış\n",
    "        self.fc3 = nn.Linear(64, 10)    # Üçüncü katman: 64 giriş, 10 çıkış (sınıf sayısı)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)  # İlk katmanla ileri geçiş\n",
    "        x = F.relu(x)    # ReLU aktivasyon fonksiyonu\n",
    "        x = self.fc2(x)  # İkinci katmanla ileri geçiş\n",
    "        x = F.relu(x)    # ReLU aktivasyon fonksiyonu\n",
    "        x = self.fc3(x)  # Üçüncü katmanla ileri geçiş\n",
    "        x = F.softmax(x, dim=1)  # Softmax ile sınıf olasılıkları\n",
    "        return x\n",
    "\n",
    "# Modeli oluşturma\n",
    "model = MLPModel()\n",
    "\n",
    "# Bir batch veri almak (DataLoader'dan)\n",
    "dataiter = iter(trainloader)  # DataLoader'dan bir iterator oluştur\n",
    "images, labels = next(dataiter)  # Bir batch al\n",
    "\n",
    "# Seçilen bir görseli al (img_idx 0, yani ilk görüntü)\n",
    "img_idx = 0\n",
    "ps = model(images[img_idx].view(1, -1))  # Görseli düzleştirip modele veriyoruz\n",
    "img = images[img_idx]  # Seçilen görseli kaydet\n",
    "\n",
    "# Tahmin ve görselleştirme fonksiyonu\n",
    "def view_classify(img, ps):\n",
    "    '''Görseli ve tahmini gösterir'''\n",
    "    ps = ps.detach().numpy().squeeze()  # Olasılıkları numpy formatına dönüştür ve squeeze ile düzleştir\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,3), ncols=2)  # 2 kolonlu bir grafik oluştur\n",
    "    ax1.imshow(img.squeeze(), cmap='gray')  # Görseli gri tonlamada göster\n",
    "    ax1.set_title(f'Tahmin: {ps.argmax()} (probability: {ps.max():.3f})')  # Tahmin edilen sınıf ve olasılığı\n",
    "    ax1.axis('off')  # Görselleştirme sırasında eksenleri kapat\n",
    "\n",
    "    ax2.barh(range(10), ps)  # Olasılıkları yatay çubuk grafik ile göster\n",
    "    ax2.set_yticks(range(10))  # Y eksenindeki etiketler\n",
    "    ax2.set_yticklabels([str(i) for i in range(10)])  # 0-9 arasında etiketler\n",
    "    ax2.set_title('Sınıf Olasılıkları')  # Başlık\n",
    "    plt.show()  # Görseli göster\n",
    "\n",
    "# Görselleştirmeyi çağırma\n",
    "view_classify(img, ps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "618e950f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrderedDict\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Giriş, gizli katman boyutları ve çıkış boyutları\u001b[39;00m\n\u001b[0;32m      5\u001b[0m input_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m784\u001b[39m  \u001b[38;5;66;03m# Örneğin, MNIST için 28x28 = 784\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:2059\u001b[0m\n\u001b[0;32m   2043\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m   2044\u001b[0m \u001b[38;5;66;03m# Import most common subpackages\u001b[39;00m\n\u001b[0;32m   2045\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2050\u001b[0m \n\u001b[0;32m   2051\u001b[0m \u001b[38;5;66;03m# needs to be before import torch.nn as nn to avoid circular dependencies\u001b[39;00m\n\u001b[0;32m   2052\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[0;32m   2053\u001b[0m     enable_grad \u001b[38;5;28;01mas\u001b[39;00m enable_grad,\n\u001b[0;32m   2054\u001b[0m     inference_mode \u001b[38;5;28;01mas\u001b[39;00m inference_mode,\n\u001b[0;32m   2055\u001b[0m     no_grad \u001b[38;5;28;01mas\u001b[39;00m no_grad,\n\u001b[0;32m   2056\u001b[0m     set_grad_enabled \u001b[38;5;28;01mas\u001b[39;00m set_grad_enabled,\n\u001b[0;32m   2057\u001b[0m )\n\u001b[1;32m-> 2059\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m   2060\u001b[0m     __config__ \u001b[38;5;28;01mas\u001b[39;00m __config__,\n\u001b[0;32m   2061\u001b[0m     __future__ \u001b[38;5;28;01mas\u001b[39;00m __future__,\n\u001b[0;32m   2062\u001b[0m     _awaits \u001b[38;5;28;01mas\u001b[39;00m _awaits,\n\u001b[0;32m   2063\u001b[0m     autograd \u001b[38;5;28;01mas\u001b[39;00m autograd,\n\u001b[0;32m   2064\u001b[0m     backends \u001b[38;5;28;01mas\u001b[39;00m backends,\n\u001b[0;32m   2065\u001b[0m     cpu \u001b[38;5;28;01mas\u001b[39;00m cpu,\n\u001b[0;32m   2066\u001b[0m     cuda \u001b[38;5;28;01mas\u001b[39;00m cuda,\n\u001b[0;32m   2067\u001b[0m     distributed \u001b[38;5;28;01mas\u001b[39;00m distributed,\n\u001b[0;32m   2068\u001b[0m     distributions \u001b[38;5;28;01mas\u001b[39;00m distributions,\n\u001b[0;32m   2069\u001b[0m     fft \u001b[38;5;28;01mas\u001b[39;00m fft,\n\u001b[0;32m   2070\u001b[0m     futures \u001b[38;5;28;01mas\u001b[39;00m futures,\n\u001b[0;32m   2071\u001b[0m     hub \u001b[38;5;28;01mas\u001b[39;00m hub,\n\u001b[0;32m   2072\u001b[0m     jit \u001b[38;5;28;01mas\u001b[39;00m jit,\n\u001b[0;32m   2073\u001b[0m     linalg \u001b[38;5;28;01mas\u001b[39;00m linalg,\n\u001b[0;32m   2074\u001b[0m     mps \u001b[38;5;28;01mas\u001b[39;00m mps,\n\u001b[0;32m   2075\u001b[0m     mtia \u001b[38;5;28;01mas\u001b[39;00m mtia,\n\u001b[0;32m   2076\u001b[0m     multiprocessing \u001b[38;5;28;01mas\u001b[39;00m multiprocessing,\n\u001b[0;32m   2077\u001b[0m     nested \u001b[38;5;28;01mas\u001b[39;00m nested,\n\u001b[0;32m   2078\u001b[0m     nn \u001b[38;5;28;01mas\u001b[39;00m nn,\n\u001b[0;32m   2079\u001b[0m     optim \u001b[38;5;28;01mas\u001b[39;00m optim,\n\u001b[0;32m   2080\u001b[0m     overrides \u001b[38;5;28;01mas\u001b[39;00m overrides,\n\u001b[0;32m   2081\u001b[0m     profiler \u001b[38;5;28;01mas\u001b[39;00m profiler,\n\u001b[0;32m   2082\u001b[0m     sparse \u001b[38;5;28;01mas\u001b[39;00m sparse,\n\u001b[0;32m   2083\u001b[0m     special \u001b[38;5;28;01mas\u001b[39;00m special,\n\u001b[0;32m   2084\u001b[0m     testing \u001b[38;5;28;01mas\u001b[39;00m testing,\n\u001b[0;32m   2085\u001b[0m     types \u001b[38;5;28;01mas\u001b[39;00m types,\n\u001b[0;32m   2086\u001b[0m     utils \u001b[38;5;28;01mas\u001b[39;00m utils,\n\u001b[0;32m   2087\u001b[0m     xpu \u001b[38;5;28;01mas\u001b[39;00m xpu,\n\u001b[0;32m   2088\u001b[0m )\n\u001b[0;32m   2089\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m windows \u001b[38;5;28;01mas\u001b[39;00m windows\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;66;03m# Quantized, sparse, AO, etc. should be last to get imported, as nothing\u001b[39;00m\n\u001b[0;32m   2093\u001b[0m \u001b[38;5;66;03m# is expected to depend on them.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\multiprocessing\\__init__.py:100\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the name of the current thread.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m        str: Name of the current thread.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_thread_name()\n\u001b[1;32m--> 100\u001b[0m init_reductions()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\multiprocessing\\reductions.py:629\u001b[0m, in \u001b[0;36minit_reductions\u001b[1;34m()\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_reductions\u001b[39m():\n\u001b[1;32m--> 629\u001b[0m     ForkingPickler\u001b[38;5;241m.\u001b[39mregister(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mEvent, reduce_event)\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_storage_classes:\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUntypedStorage\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'cuda'"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "\n",
    "# Giriş, gizli katman boyutları ve çıkış boyutları\n",
    "input_size = 784  # Örneğin, MNIST için 28x28 = 784\n",
    "hidden_sizes = [128, 64]  # Örnek gizli katman boyutları\n",
    "output_size = 10  # 10 sınıf (MNIST gibi)\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    (\"fcl1\", nn.Linear(input_size, hidden_sizes[0])),  # İlk tam bağlantılı katman\n",
    "    (\"relu1\", nn.ReLU()),  # İlk ReLU aktivasyonu\n",
    "    (\"fcl2\", nn.Linear(hidden_sizes[0], hidden_sizes[1])),  # İkinci tam bağlantılı katman\n",
    "    (\"relu2\", nn.ReLU()),  # İkinci ReLU aktivasyonu\n",
    "    (\"output\", nn.Linear(hidden_sizes[1], output_size)),  # Çıkış katmanı\n",
    "    (\"softmax\", nn.Softmax(dim=1))  # Softmax çıkış\n",
    "]))\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dc4c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Kodun Açıklaması:\n",
    "OrderedDict Kullanımı:\n",
    "\n",
    "OrderedDict, Python'un standart dict sınıfına benzer, ancak eklediğiniz öğelerin sırasını korur. Burada, OrderedDict, modelin katmanlarını belirli bir sırayla tutmak için kullanılıyor.\n",
    "nn.Sequential:\n",
    "\n",
    "nn.Sequential, verilen katmanları sırayla birleştirir ve bunları otomatik olarak birbirine bağlar. Burada, modeldeki her katman bir önceki katmandan çıktı alacak şekilde sıralanır.\n",
    "Katmanlar:\n",
    "\n",
    "(\"fcl\", nn.Linear(input_size, hidden_sizes[0])):\n",
    "\n",
    "İlk katman, input_size giriş boyutuna sahip, ve hidden_sizes[0] kadar çıkış üretecek bir fully connected (tam bağlantılı) katmandır.\n",
    "(\"relu1\", nn.ReLU()):\n",
    "\n",
    "İkinci katman, ReLU aktivasyon fonksiyonunu uygular. Bu, doğrusal olmayan bir aktivasyon fonksiyonudur ve genellikle sinir ağlarında kullanılır.\n",
    "(\"fcl2\", nn.Linear(input_size, hidden_sizes[0])):\n",
    "\n",
    "Burada bir hata var. input_size'ı hidden_sizes[0]'a bağlayan ikinci bir fully connected katmanı tanımlıyorsunuz, ancak genellikle buradaki giriş boyutunun, önceki katmandan gelen çıkışa göre olması gerekir. Bu, bir hata olabilir.\n",
    "(\"relu2\", nn.ReLU()):\n",
    "\n",
    "İkinci ReLU aktivasyonu, ikinci fully connected katmandan gelen çıktıya uygulanır.\n",
    "(\"output\", nn.Linear(output_sizes[1], output_size)):\n",
    "\n",
    "Çıktı katmanı, output_sizes[1] giriş boyutuna sahip ve output_size kadar çıktı veren bir fully connected katmandır.\n",
    "(\"softmax\", nn.Softmax(dim=1)):\n",
    "\n",
    "Softmax fonksiyonu, her sınıf için olasılık değerlerini hesaplar ve toplamının 1 olmasını sağlar. dim=1 parametresi, her örnek için (batch içindeki her satır) softmax işlemi yapılacağını belirtir."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
